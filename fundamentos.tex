\chapter{Fundamentos teóricos}

\section{Redes neurais artificiais}

Dentro da Inteligência artificial, mais especificamente no contexto do
aprendizado de máquina, as redes neurais artificiais são sistemas computacionais
inspirados na estrutura do cérebro, em particular dos neurônios, que adquirem
conhecimento através da experiência.

As redes neurais se assemelham a grafos direcionados, onde os nós são os
neurônios, ou unidades de processamento, que possuem uma quantidade indefinida
de conexões de entrada e saída. As conexões são o equivalente às arestas do
grafo, e são responsáveis por transmitir informações entre os neurônios, podendo
amplificar ou reduzir a acuidade destas informações.

Sinais de entrada provenientes de fora da rede chegam por meio de conexões
originadas do mundo externo, de modo semelhante, saídas da rede para o mundo
externo são conexões que deixam a rede.

A configuração da rede, ou seja, os peso atual das conexões, determina como os
dados de entrada irão ativar os diferentes neurônios e gerar um determinado
resultado. Para grande maioria dos tipos de redes neurais, uma configuração
particular é obtida através de um algoritmo de treinamento. O treinamento em
geral busca reforçar as conexões que geram bons resultados e penalizar as que
não geram.

Estre as tarefas para as quais uma rede neural é adequada se
incluem: classificação, reconhecimento de padrões, predições, otimização
e filtragem de ruído.

\section{Principais tipos de redes neurais}

Dentre a grande variedade de tipos de redes neurais artificiais, as mais
importantes, seja por sua contribuição teórica ou pela praticidade, são:

\subsection{Rede perceptron multicamada}

A perceptron multicamada é (a) uma rede direta, isto é, o sinal passa da entrada
até a saída sem ciclos; (b) possui camadas intermediárias de neurônios entre as
camadas de entrada e saída, ditas camadas ocultas; (c) utiliza funções de
ativação não lineares, comumente a função sigmoide e (d) os neurônios são
altamente conectados, em geral cada neurônio é conectado a todos os neurônios
da camada anterior e da camada seguinte.

A presença de múltiplas camadas permite a este tipo de rede resolver uma enorme
variedade de problemas, ou em outros termos, reconhecer uma vasta variedade de
padrões. As redes multicamadas são computacionalmente completas, ou seja, são
equivalentes à classe das máquinas de Turing.

A retropropagação é o algoritmo de treinamento mais utilizado para esta variante
de rede neural. Este algoritmo é dividido em dois passos, no primeiro a rede é
alimentada com um dos exemplos, o resultado é capturado e comparado com o valor
esperado, com isso o erro geral da rede é calculado; segue-se então ao segundo
passo, que atualiza os pesos sinápticos penalizando cada neurônio segundo sua
influência no erro geral, essa etapa é feita da camada de saída para a de
entrada, retroativamente.

\subsection{Rede de Hopfield}

A rede de Hofield é (a) uma forma de rede neural recorrente, isto é,
determinadas conexões realimentam alguns neurônios, formando ciclos na rede; (b)
apresenta um atraso temporal, ou seja, a propagação dos sinais não é instantânea
e (c) a saída é um estado de convergência, isto é, após se apresentar uma entrada
a rede opera em ciclos até que a saída não mude mais, situação onde se diz que a
rede alcançou o estado de equilíbrio.

A rede de Hopfield funciona como uma memória endereçada por conteúdo, ou memória
associativa, por exemplo, muitas vezes lembramos de fatos inteiros apenas com uma
pequena lembrança do acontecimento. Uma memória associativa é, deste modo, um
conjunto de padrões armazenados de tal modo que, quando se apresenta um novo padrão,
a resposta será o padrão armazenado que seja mais parecido a este que foi apresentado.

Geralmente, a rede de Hopfield não possui um método de aprendizado associado,
os pesos sinápticos são calculados por métodos matemáticos provenientes de sua
definição formal. A definição formal garante que a rede sempre irá convergir,
contudo, em algumas situações esta convergência pode não ocorrer para o padrão
mais próximo da entrada, e ainda não existe um método conhecido que resolva
este problema.

\subsection{Redes de Kohonen}

As redes de Kohonen apresentam apenas duas camadas de neurônios, a camada de
entrada e a de saída. A camada de saída é uma espécie de malha de neurônios não
conectados entre si, mas amplamente conectados com os neurônios da camada de
entrada. Esta malha funciona como um mapa, onde para cada padrão de entrada
apenas um neurônio é ativado, padrões semelhantes ativam neurônios dentro de
uma mesma região da malha.

As redes de Kohonen possuem um algoritmo próprio de treinamento, dividido em
três etapas; na primeira, chamado de processo competitivo, uma determinada entrada
ativa apenas um neurônio da malha; na segunda, chamado de processo cooperativo,
o neurônio escolhido estabelece uma vizinhança de neurônios que serão ajustados
para, junto com ele, identificar padrões semelhantes ao que foi apresentado; e
por fim, na terceira etapa, chamada de processo adaptativo, os pesos são
atualizados com base no neurônio vencedor e na vizinhança topológica. Este
algoritmo de treinamento é dito não supervisionado, pois não depende de um
par \textit{(entrada, saída esperada)}, já que a própria rede estabelece como
será a configuração dos resultados.

\section{Redes neurais de Kohonen}

Esta seção irá apresentar mais detalhadamente como é a configuração de uma rede
de Kohonen, seu algoritmo de treinamento e os usos comuns deste tipo de rede.

\subsection{Topologia de uma rede de Kohonen}

Como dito anteriormente, a rede de Kohonen apresenta apenas duas camadas de
neurônios, a camada de entrada e a camada de saída. A camada de entrada deve
possuir tantos neurônios quanto forem à quantidade de elementos do padrão de
entrada. A camada de saída é uma grade de geometria livre, geralmente
retangular, de neurônios que não estão ligados entre si, mas estão, cada um,
ligados a todos os neurônios da camada de entrada. As conexões apresentam pesos
para escalar o sinal enviado.

\subsection{Treinamento da rede}

O treinamento requer que os pesos sinápticos sejam iniciados com valores bem
pequenos, para que a rede não apresente inicialmente nenhuma configuração. Três
processos são executados para cada entrada do conjunto de treinamento, o
processo competitivo, o processo cooperativo e o processo adaptativo.

\subsubsection{Processo competitivo}

Quando uma entrada $ x = \left[x_1, x_2, ..., x_n\right] $ é apresentado à
rede, o neurônio da grade que melhor responder a este padrão será ativado, este
neurônio é dito vencedor, e será recompensado ajustando-se seus componentes
para mais próximo do vetor de entrada.

O critério escolhido para determinar o neurônio vencedor é a distância
euclidiana entre o vetor de entradas e o vetor de pesos das sinapses do
neurônio, como indicado na equação \ref{eq_dit_ecl}:

\begin{equation}\label{eq_dit_ecl}
d_i(t) = \sqrt{\sum_{j = 1}^N \left( x_j(t) - w_{ij}(t) \right)^2}
\end{equation}

Onde:

\begin{itemize}
\item $ d_i(t) $ é a distância euclidiana entre o vetor de pesos do
neurônio $ i $ e o vetor de entradas na iteração $ t $;
\item $ i $ é o índice do neurônio da grade;
\item $ j $ é o índice do neurônio de entrada;
\item $ N $ é o número de entradas;
\item $ x_j(t) $ é o sinal de entrada na entrada $ j $ na iteração $ t $;
\item $ w_{ij}(t) $ é o valor do peso sináptico entre o neurônio de
entrada $ j $ e o neurônio da grade $ i $ na iteração $ t $.
\end{itemize}

\subsubsection{Processo cooperativo}

Estudos biológicos indicam que ao ser excitado, um neurônio estimula seus
vizinhos topológicos, de forma que quanto mais próximo um neurônio está do
neurônio ativo, mais excitado pelo estímulo do neurônio ativo ele é. O processo
cooperativo busca simular este mecanismo biológico.

Em termos matemáticos, o que se deseja é um parâmetro $ h_{ik} $ , dito
\textit{vizinhança topológica}, que indica o gral de cooperação entre o
neurônio vencedor $ i $ e o seu vizinho $ k $, que deve ser simétrico em relação
ao neurônio $ k $ e deve decrescer constantemente com o aumento da
distância $ l_{ik} $ , até que $ \lim\limits_{ l_{ik} \to \infty } h_{ik} = 0 $ .
A função gaussiana \ref{eq_gauss} atende a estas duas exigências:

\begin{equation}\label{eq_gauss}
h_{ik} = e^{ \left( \frac{ l_{ik}^2 }{ 2 \sigma^2 } \right) }
\end{equation}


O parâmetro $ \sigma $ é denominado \textit{largura efetiva da vizinhança},
e deve diminuir a cada iteração, indicando uma tendência de especialização da
rede. Neste trabalho o parâmetro O é a equação \ref{eq_leg_eft}:

\begin{equation}\label{eq_leg_eft}
\sigma(t) = \sigma_0 e^{ t / \tau_l }
\end{equation}

Onde:

\begin{itemize}
\item $ \sigma_0 $ é o valor inicial de $ \sigma $;
\item $ t $ é a iteração atual;
\item $ \tau_l $ é uma constante de tempo.
\end{itemize}

\subsubsection{Processo adaptativo}

O processo adaptativo atualiza os pesos sinápticos a cada iteração, levando em
consideração o neurônio vencedor e a vizinhança topológica. O ajuste dos pesos
deve decrescer com o tempo, para evitar que novos dados comprometam seriamente
o conhecimento já adquirido, substituindo padrões já estabelecidos por novos.
Algo semelhante ocorre com o cérebro humano, ao decorrer do envelhecimento o
aprendizado vai se tornando mais difícil.

O ajuste $ \Delta w_{ij} $ que a sinapse entre o neurônio de entrada $ i $ e
um neurônio da malha $ j $ deve sofrer é expresso pela equação \ref{eq_ajus}:

\begin{equation}\label{eq_ajus}
\Delta w_{ij} = \eta(t) h_{ik}(t) (x_j - w_{ij})
\end{equation}

Onde $ h_{ik}(t) $ é o parâmetro vizinhança topológica na iteração $ t $ ,
referente ao neurônio vencedor $ k $ . O
parâmetro \textit{taxa de aprendizagem} $ \eta(t) $ é definido pela
expressão \ref{eq_tx_aprd}:

\begin{equation}\label{eq_tx_aprd}
\eta(t) = \eta_0 e^{ t / \tau_l }, \eta_0 \in [0, 1]
\end{equation}

Onde $ \tau_l $ é uma constante de tempo.

